import { useState, useCallback } from 'react';
import * as tf from '@tensorflow/tfjs';
import { loadImageFromBase64, preprocessImage } from '../utils/imagePreprocessing';
import { PredictionResult } from '../types';

interface UseModelInferenceProps {
  model: tf.LayersModel | null;
}

interface UseModelInferenceReturn {
  predict: (imageData: string) => Promise<PredictionResult>;
  isLoading: boolean;
  error: string | null;
}

/**
 * ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚’è¡Œã†ã‚«ã‚¹ã‚¿ãƒ ãƒ•ãƒƒã‚¯
 */
export function useModelInference({ model }: UseModelInferenceProps): UseModelInferenceReturn {
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const predict = useCallback(
    async (imageData: string): Promise<PredictionResult> => {
      if (!model) {
        throw new Error('ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“');
      }

      setIsLoading(true);
      setError(null);

      try {
        console.log('ğŸ” æ¨è«–ã‚’é–‹å§‹...');

        // Base64ç”»åƒã‚’HTMLImageElementã«å¤‰æ›
        const image = await loadImageFromBase64(imageData);
        console.log(`  ç”»åƒã‚µã‚¤ã‚º: ${image.width}x${image.height}`);

        // ç”»åƒã®å‰å‡¦ç†
        const preprocessed = preprocessImage(image, 224);
        console.log('  å‰å‡¦ç†å®Œäº†');

        // ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ  [224, 224, 3] â†’ [1, 224, 224, 3]
        const batchedTensor = preprocessed.expandDims(0);

        // æ¨è«–å®Ÿè¡Œ
        const startTime = performance.now();
        const prediction = model.predict(batchedTensor) as tf.Tensor;
        const endTime = performance.now();

        console.log(`  æ¨è«–æ™‚é–“: ${(endTime - startTime).toFixed(2)}ms`);

        // çµæœã‚’å–å¾—
        const probabilities = await prediction.data();

        // ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        preprocessed.dispose();
        batchedTensor.dispose();
        prediction.dispose();

        // çµæœã‚’è§£æ
        // ã‚¯ãƒ©ã‚¹0: not-carbonara, ã‚¯ãƒ©ã‚¹1: carbonara
        const notCarbonaraProbability = probabilities[0];
        const carbonaraProbability = probabilities[1];

        const isCarbonara = carbonaraProbability > notCarbonaraProbability;
        const confidence = Math.max(carbonaraProbability, notCarbonaraProbability);

        console.log(`  çµæœ: ${isCarbonara ? 'ã‚«ãƒ«ãƒœãƒŠãƒ¼ãƒ©' : 'ã‚«ãƒ«ãƒœãƒŠãƒ¼ãƒ©ã§ã¯ãªã„'}`);
        console.log(`  ç¢ºä¿¡åº¦: ${(confidence * 100).toFixed(2)}%`);
        console.log(`  è©³ç´°: ã‚«ãƒ«ãƒœãƒŠãƒ¼ãƒ©=${(carbonaraProbability * 100).toFixed(2)}%, ãã®ä»–=${(notCarbonaraProbability * 100).toFixed(2)}%`);

        const result: PredictionResult = {
          isCarbonara,
          confidence,
          probabilities: {
            carbonara: carbonaraProbability,
            notCarbonara: notCarbonaraProbability,
          },
        };

        setIsLoading(false);
        return result;
      } catch (err) {
        const errorMessage = err instanceof Error ? err.message : 'æ¨è«–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ';
        console.error('âŒ æ¨è«–ã‚¨ãƒ©ãƒ¼:', err);
        setError(errorMessage);
        setIsLoading(false);
        throw err;
      }
    },
    [model]
  );

  return { predict, isLoading, error };
}
