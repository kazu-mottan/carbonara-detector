import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-backend-wasm';

/**
 * TensorFlow.jsãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
 * WASMãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã€ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ
 */
export async function loadModel(): Promise<tf.LayersModel> {
  try {
    console.log('ğŸ”§ TensorFlow.js ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’åˆæœŸåŒ–ä¸­...');

    // WASMãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’è¨­å®šï¼ˆé«˜é€ŸåŒ–ï¼‰
    await tf.setBackend('wasm');
    await tf.ready();

    console.log(`âœ… ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: ${tf.getBackend()}`);
    console.log('ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...');

    // ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    const model = await tf.loadLayersModel('/models/model.json');

    console.log('âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†');
    console.log('ğŸ”¥ ãƒ¢ãƒ‡ãƒ«ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ä¸­...');

    // ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ï¼ˆåˆå›æ¨è«–ã®é…å»¶ã‚’é˜²ãï¼‰
    const warmupTensor = tf.zeros([1, 224, 224, 3]);
    const warmupResult = model.predict(warmupTensor);

    // ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    warmupTensor.dispose();
    if (Array.isArray(warmupResult)) {
      warmupResult.forEach(t => t.dispose());
    } else {
      warmupResult.dispose();
    }

    console.log('âœ… ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Œäº†');
    console.log('ğŸ‰ ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ãŒæ•´ã„ã¾ã—ãŸï¼');

    return model;
  } catch (error) {
    console.error('âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:', error);
    throw new Error(
      `ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n` +
      `ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒ public/models/ ã«é…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n` +
      `è©³ç´°: ${error instanceof Error ? error.message : String(error)}`
    );
  }
}

/**
 * ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
 */
export function logMemoryUsage(): void {
  const memoryInfo = tf.memory();
  console.log('ğŸ“Š TensorFlow.js ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡:');
  console.log(`  ãƒ†ãƒ³ã‚½ãƒ«æ•°: ${memoryInfo.numTensors}`);
  console.log(`  ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒ•ã‚¡æ•°: ${memoryInfo.numDataBuffers}`);
  console.log(`  ä½¿ç”¨ãƒ¡ãƒ¢ãƒª: ${(memoryInfo.numBytes / 1024 / 1024).toFixed(2)} MB`);
}
